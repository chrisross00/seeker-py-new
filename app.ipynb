{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project setup, imports, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# approach 2 - PRAW\n",
    "import requests\n",
    "import praw\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import json\n",
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "from collections import defaultdict\n",
    "\n",
    "# note that CLIENT_ID refers to 'personal use script' and SECRET_TOKEN to 'token'\n",
    "CLIENT_ID = 'Mx4J1DKZ856aT1ug9glOdA'\n",
    "SECRET_TOKEN = 'j0a57wDUiC9TSDQhx1CYNz4jl65Aiw'\n",
    "USERNAME = 'malconst'\n",
    "PASSWORD = '7(>vAn!GqC1\"'\n",
    "USER_AGENT = 'Seeker/0.0.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish authorized Reddit instance\n",
    "reddit = praw.Reddit(\n",
    "    client_id = CLIENT_ID,\n",
    "    client_secret = SECRET_TOKEN,\n",
    "    user_agent = USER_AGENT,\n",
    "    username = USERNAME,\n",
    "    password = PASSWORD\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Reddit\n",
    "PRAW Search doucmentation https://praw.readthedocs.io/en/latest/code_overview/models/subreddit.html?highlight=search#praw.models.Subreddit.search\n",
    "\n",
    "*Important:* the search function in this implementation is a method on the Subreddit object, not Subreddits\n",
    "\n",
    "For now, implemented hashing as described here https://www.codegrepper.com/code-examples/python/python+convert+string+to+hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pythonspot.com/save-a-dictionary-to-a-file/\n",
    "\n",
    "https://www.geeksforgeeks.org/how-to-read-dictionary-from-file-in-python/\n",
    "\n",
    "https://stackoverflow.com/questions/2132985/how-to-import-or-include-data-structures-e-g-a-dict-into-a-python-file-from-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable setup and stuff\n",
    "subreddit = reddit.subreddit(\"mechmarket\") #set the subreddit object\n",
    "\n",
    "# Access the database (local json object)\n",
    "with open('dbdict.json') as f: #load it to f\n",
    "    t = f.read() #read it to t\n",
    "stored_search_test = json.loads(t) #turn t into a dictionary and store it\n",
    "\n",
    "# Variable setup\n",
    "current_hash_list = [] #to store current db hashes\n",
    "searches = [] #holder for final storage; kept searches only\n",
    "all_searches = [] #holder for analysis; all searches\n",
    "search_queries = [\"olivia\",\"9009\",\"hammerhead\"] #list of the queries to search for (move to config.json)\n",
    "limit = 3 #limit for the queries (move to config.json)\n",
    "i_len = len(stored_search_test['searches']) #length of the current db searches\n",
    "\n",
    "#store db hashes\n",
    "for i in range(i_len):\n",
    "    j_len = len(stored_search_test['searches'][i]) #length of the j loop for some reason this works lol\n",
    "    for j in range(j_len):\n",
    "        k_len = len(stored_search_test['searches'][i][j]['search_results'])\n",
    "        for k in range(k_len):\n",
    "            current_hash_list.append(stored_search_test['searches'][i][j]['search_results'][k]['body']['hash']) #store the hash to the current_hash_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search\n",
    "for query in search_queries: #work through the list of queries\n",
    "    results = [] #holder for handling the sets of search results stemming from each query\n",
    "    for result in subreddit.search(query,sort=\"new\", limit=limit): #make a hash in the same way as \n",
    "        # Structure the data before storing - there ahs to be a better way than this... like convering to JSON upstream\n",
    "        result_id = str(result)\n",
    "        to_hash = str(result.author)+ str(result.title)+ str(result.url)\n",
    "        hash_object = hashlib.sha256(to_hash.encode('utf-8')) #\n",
    "        hex_dig = hash_object.hexdigest() #the hash for this search result\n",
    "        # all_searches.append({'result_id': result_id, 'body': body}) #could delete this, don't really need it\n",
    "\n",
    "        #Evaluate the new hash against the hash in the database search results\n",
    "        \n",
    "        # Check to see if this search result's hash is in the list. If yes ignore it, if it's not, add it to the db\n",
    "        if hex_dig in current_hash_list:\n",
    "            print('already')\n",
    "            break\n",
    "        elif hex_dig not in current_hash_list:\n",
    "            print('else if')\n",
    "            body = {\n",
    "                'author':result.author.name,\n",
    "                'title':result.title,\n",
    "                'created date': datetime.fromtimestamp(result.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'url':result.url,\n",
    "                'hash':hex_dig\n",
    "            }\n",
    "            results.append({'result_id': result_id, 'body': body}) #just bundle the result_id and body into its own result object and add it to the the results list\n",
    "    if results:\n",
    "        searches.append({'query':query,'search_results':results})\n",
    "if searches:\n",
    "    stored_search_test['searches'].append(searches) # update the stored_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store dictionary somewhere\n",
    "# Save dictionary\n",
    "data = json.dumps(stored_search_test) #the final updated database\n",
    "f = open(\"dbdict.json\",\"w\")\n",
    "f.write(data)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Approach 1 - \n",
    "# import requests\n",
    "# import praw\n",
    "\n",
    "# # note that CLIENT_ID refers to 'personal use script' and SECRET_TOKEN to 'token'\n",
    "# CLIENT_ID = 'Mx4J1DKZ856aT1ug9glOdA'\n",
    "# SECRET_TOKEN = 'j0a57wDUiC9TSDQhx1CYNz4jl65Aiw'\n",
    "# USERNAME = 'malconst'\n",
    "# PASSWORD = '7(>vAn!GqC1\"'\n",
    "# USER_AGENT = 'Seeker/0.0.1'\n",
    "\n",
    "# auth = requests.auth.HTTPBasicAuth(CLIENT_ID, SECRET_TOKEN)\n",
    "\n",
    "# # here we pass our login method (password), username, and password\n",
    "# data = {'grant_type': 'password',\n",
    "#         'username': USERNAME,\n",
    "#         'password': PASSWORD}\n",
    "\n",
    "# # setup our header info, which gives reddit a brief description of our app\n",
    "# headers = {'User-Agent': 'Seeker/0.0.1'}\n",
    "\n",
    "# # send our request for an OAuth token\n",
    "# res = requests.post('https://www.reddit.com/api/v1/access_token',\n",
    "#                     auth=auth, data=data, headers=headers)\n",
    "\n",
    "# # convert response to JSON and pull access_token value\n",
    "# TOKEN = res.json()\n",
    "\n",
    "# # add authorization to our headers dictionary\n",
    "# headers = {**headers, **{'Authorization': f\"bearer {TOKEN}\"}}\n",
    "\n",
    "# res = requests.get(\"https://oauth.reddit.com/r/python/hot\",\n",
    "#                    headers=headers).json()\n",
    "\n",
    "# print(res.url)  # let's see what we get\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "181c2df457f0d00d103b4e25afefeabba3a097333510e9abb596c945bad2abe4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
